{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-labelficlassification\n",
    "\n",
    "in which each instance can be assigned a subset of the set of classes. Problem transformation methods are techniques that cast the original multi-label problem as a set of single-label classi cation problems. \n",
    "\n",
    "The first problem transformation method that we will review converts each set of labels encountered in the training data to a single label. For example, consider a multi-label classi cation problem in which news articles must be assigned to one or more categories from\n",
    "a set. The following training data contains seven articles that can pertain to one or more of the  ve categories.\n",
    "\n",
    "\n",
    "A second problem transformation is to train one binary classi er for each of the labels in the training set. Each classi er predicts whether or not the instance belongs to one label. Our example would require  ve binary classi ers; the  rst classi er would predict whether or not an instance should be classi ed as Local, the second classi er would predict whether or not an instance should be classi ed as US, and so on. The  nal prediction is the union of the predictions from all of the binary classi ers. The transformed training data is shown in the previous  gure. This problem transformation ensures that the single-label problems will have the same number of training examples as the multilabel problem, but ignores relationships between the labels.\n",
    "\n",
    "# Multi-label classi cation performance metrics\n",
    "\n",
    "Multi-label classi cation problems must be assessed using different performance measures than single-label classi cation problems. Two of the most common performance metrics are Hamming loss and Jaccard similarity. Hamming loss is the average fraction of incorrect labels. Note that Hamming loss is a loss function, and that the perfect score is zero. Jaccard similarity, or the Jaccard index, is the size of the intersection of the predicted labels and the true labels divided by the size of the union of the predicted and true labels. It ranges from zero to one, and one is the perfect score. Jaccard similarity is calculated by the following equation:\n",
    "$$J(Predicted,True)= \\frac{|Predicted∩True|}{|Predicted ∪ True|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
